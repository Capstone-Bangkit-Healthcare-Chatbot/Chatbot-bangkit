{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7639866,"sourceType":"datasetVersion","datasetId":841565}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install rouge-score sacrebleu evaluate torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:02:27.575862Z","iopub.execute_input":"2024-11-28T16:02:27.576735Z","iopub.status.idle":"2024-11-28T16:02:39.391461Z","shell.execute_reply.started":"2024-11-28T16:02:27.576686Z","shell.execute_reply":"2024-11-28T16:02:39.390310Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ffd4dc42c903a400e6a82125a1551777098d557e99961a7f3e38d1cc32b12508\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: torchsummary, portalocker, sacrebleu, rouge-score, evaluate\nSuccessfully installed evaluate-0.4.3 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3 torchsummary-1.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport evaluate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom transformers import BartConfig,BartForConditionalGeneration,BartTokenizer\nfrom transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, TrainerCallback, Seq2SeqTrainingArguments\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset\nfrom torchsummary import summary\n\nfrom collections import defaultdict\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:02:39.393097Z","iopub.execute_input":"2024-11-28T16:02:39.393382Z","iopub.status.idle":"2024-11-28T16:02:58.453412Z","shell.execute_reply.started":"2024-11-28T16:02:39.393352Z","shell.execute_reply":"2024-11-28T16:02:58.452743Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Cleaning Data","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/layoutlm/medquad.csv')\nprint(\"Data Sample\")\nprint(df.head())\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\ntotal_duplicates = df.duplicated(['question'], keep=False)\nprint(f\"Total duplicates in 'question' column: {total_duplicates.sum()}\")\nduplicates = df.duplicated()\nprint(f\"Number of duplicate rows: {duplicates.sum()}\")\ndf = df.drop_duplicates()\ndf.reset_index(drop=True, inplace=True)\nprint(\"Table Info\")\nprint(df.info())\ndf = df.drop_duplicates(subset='question', keep='first').reset_index(drop=True)\ndf = df.drop_duplicates(subset='answer', keep='first').reset_index(drop=True)\ndf.dropna(inplace=True)\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\nprint(df.info())\ndf['question'] = df['question'].fillna('')\ndf['answer'] = df['answer'].fillna('')\ndf['prompt'] = df['question'] + ' ' + df['answer']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:03:25.199058Z","iopub.execute_input":"2024-11-28T16:03:25.199844Z","iopub.status.idle":"2024-11-28T16:03:25.802904Z","shell.execute_reply.started":"2024-11-28T16:03:25.199810Z","shell.execute_reply":"2024-11-28T16:03:25.801819Z"}},"outputs":[{"name":"stdout","text":"Data Sample\n                                 question  \\\n0                What is (are) Glaucoma ?   \n1                  What causes Glaucoma ?   \n2     What are the symptoms of Glaucoma ?   \n3  What are the treatments for Glaucoma ?   \n4                What is (are) Glaucoma ?   \n\n                                              answer           source  \\\n0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n\n  focus_area  \n0   Glaucoma  \n1   Glaucoma  \n2   Glaucoma  \n3   Glaucoma  \n4   Glaucoma  \nNull Value Data\nquestion       0\nanswer         5\nsource         0\nfocus_area    14\ndtype: int64\nTotal duplicates in 'question' column: 2319\nNumber of duplicate rows: 48\nTable Info\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16364 entries, 0 to 16363\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   question    16364 non-null  object\n 1   answer      16359 non-null  object\n 2   source      16364 non-null  object\n 3   focus_area  16350 non-null  object\ndtypes: object(4)\nmemory usage: 511.5+ KB\nNone\nNull Value Data\nquestion      0\nanswer        0\nsource        0\nfocus_area    0\ndtype: int64\n<class 'pandas.core.frame.DataFrame'>\nIndex: 14457 entries, 0 to 14463\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   question    14457 non-null  object\n 1   answer      14457 non-null  object\n 2   source      14457 non-null  object\n 3   focus_area  14457 non-null  object\ndtypes: object(4)\nmemory usage: 564.7+ KB\nNone\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Architecting Model","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/bart-large\"\nconfig = BartConfig.from_pretrained(model_name)\nconfig.dropout_rate = 0.2\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name, config=config)\n\n# Tie weights explicitly\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Print model architecture summary\n# Print detailed model summary\nprint(\"\\nDetailed Model Summary:\")\nprint(\"=\" * 50)\n\ndef summarize_model_by_type(model):\n    layer_summary = defaultdict(int)\n    param_summary = defaultdict(int)\n\n    for name, module in model.named_modules():\n        layer_type = type(module).__name__\n        layer_summary[layer_type] += 1\n        param_summary[layer_type] += sum(p.numel() for p in module.parameters())\n\n    print(f\"{'Layer Type':<30}{'Count':<10}{'Parameters':<15}\")\n    print(\"=\" * 55)\n    for layer_type, count in layer_summary.items():\n        print(f\"{layer_type:<30}{count:<10}{param_summary[layer_type]:<15,}\")\n\nsummarize_model_by_type(model)\n\n# Preprocess function for seq2seq task\ndef preprocess_function(batch):\n    inputs = [f\"question: {q}\" for q in batch['question']]\n    targets = [f\"{a}\" for a in batch['answer']]\n    \n    model_inputs = tokenizer(\n        inputs,\n        max_length=128,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\",\n    )\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets,\n            max_length=64,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n    \n    labels[\"input_ids\"][labels[\"input_ids\"] == tokenizer.pad_token_id] = -100\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Train-test split\ntrain_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\n# Preprocess datasets\ntrain_dataset = train_dataset.map(\n    preprocess_function,\n    batched=True,\n    batch_size=32,  \n    remove_columns=train_dataset.column_names,\n    num_proc=4,   \n)\n\nval_dataset = val_dataset.map(\n    preprocess_function,\n    batched=True,\n    batch_size=32,  \n    remove_columns=val_dataset.column_names,\n    num_proc=4,  \n)\n\n\n# Training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"steps\",\n    eval_steps=1000,  \n    save_steps=1000,  \n    save_total_limit=2,  \n    learning_rate=3e-5,   \n    num_train_epochs=1,   \n    per_device_train_batch_size=4,   \n    per_device_eval_batch_size=4, \n    lr_scheduler_type=\"cosine_with_restarts\",  \n    warmup_ratio=0.15,  \n    weight_decay=0.01,\n    predict_with_generate=True,\n    fp16=True,   \n    logging_dir=\"./logs\",\n    logging_steps=50,  \n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_exact_match\",\n    greater_is_better=True,\n    report_to=\"none\",\n    gradient_accumulation_steps=1,   \n    max_grad_norm=0.5,\n    optim=\"adamw_torch_fused\",  \n    generation_max_length=64,  \n    generation_num_beams=4,\n    dataloader_num_workers=4,   \n    group_by_length=True, \n    remove_unused_columns=True,\n)\n\ntraining_args.label_smoothing_factor = 0.1\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model,  \n    padding='longest',  \n)\n\n# Create function to show exact match, BLEU and ROUGE\ndef compute_metrics(eval_pred, tokenizer):\n    # Unpack predictions and labels\n    predictions, labels = eval_pred\n    \n    # Handle case where predictions might be a tuple\n    if isinstance(predictions, tuple):\n        predictions = predictions[0]\n    \n    # Decode predictions\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    \n    # Replace -100 in labels with pad token for decoding\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Text normalization function\n    def normalize_text(text):\n        \"\"\"Normalize text for consistent comparison\"\"\"\n        text = text.strip().lower()\n        text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespaces\n        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n        return text\n    \n    # Normalize predictions and labels\n    decoded_preds = [normalize_text(pred) for pred in decoded_preds]\n    decoded_labels = [normalize_text(label) for label in decoded_labels]\n    \n    # Compute Exact Match\n    exact_matches = [pred == label for pred, label in zip(decoded_preds, decoded_labels)]\n    exact_match_accuracy = np.mean(exact_matches)\n    \n    # Load metrics\n    bleu_metric = evaluate.load(\"bleu\")\n    rouge_metric = evaluate.load(\"rouge\")\n    \n    # Compute BLEU score\n    bleu = bleu_metric.compute(\n        predictions=decoded_preds, \n        references=[[label] for label in decoded_labels]\n    )\n    bleu_score = bleu[\"bleu\"]\n    \n    # Compute ROUGE score\n    rouge = rouge_metric.compute(\n        predictions=decoded_preds, \n        references=decoded_labels\n    )\n    rouge_l = rouge[\"rougeL\"]\n    \n    return {\n        \"exact_match\": exact_match_accuracy,\n        \"BLEU\": bleu_score,\n        \"ROUGE-L\": rouge_l,\n    }\n\n# Initialize data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    padding='longest',\n    return_tensors=\"pt\"\n)\n\n# Initialize trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer)\n)\n\n# Train the model\ntrainer.train()\n\n# Save the model and tokenizer\ntrainer.save_model(\"./chatbot_model\")\ntokenizer.save_pretrained(\"./chatbot_tokenizer\")\nmodel_path = \"./chatbot_model.h5\"\ntorch.save(model.state_dict(), model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:24:37.828491Z","iopub.execute_input":"2024-11-28T16:24:37.829163Z","iopub.status.idle":"2024-11-28T16:54:23.513727Z","shell.execute_reply.started":"2024-11-28T16:24:37.829124Z","shell.execute_reply":"2024-11-28T16:54:23.512667Z"}},"outputs":[{"name":"stdout","text":"\nDetailed Model Summary:\n==================================================\nLayer Type                    Count     Parameters     \n=======================================================\nBartForConditionalGeneration  1         406,291,456    \nBartModel                     1         406,291,456    \nBartScaledWordEmbedding       1         51,471,360     \nBartEncoder                   1         203,678,720    \nBartLearnedPositionalEmbedding2         2,101,248      \nModuleList                    2         352,714,752    \nBartEncoderLayer              12        151,154,688    \nBartSdpaAttention             36        151,142,400    \nLinear                        193       404,063,232    \nLayerNorm                     62        126,976        \nGELUActivation                24        0              \nBartDecoder                   1         254,084,096    \nBartDecoderLayer              12        201,560,064    \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/12288 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e70a8f0e4954df4a46a482852ff92d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/2169 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d4bc86a38942ff90560019ce57815c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1536' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1536/1536 28:48, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Exact Match</th>\n      <th>Bleu</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>2.965500</td>\n      <td>2.902961</td>\n      <td>0.001383</td>\n      <td>0.269141</td>\n      <td>0.374712</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae9f76350be644eaae7da8010cf58870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ea4b2afd0741709221fc9fd77c3a1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66c03554f00542d5b656b7b7022a7c55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9445ebc211eb437f9e5e56bc80dcae30"}},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Generate Responds","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/working/chatbot_model\"\ntokenizer_path = \"/kaggle/working/chatbot_tokenizer\"\n\ntokenizer = BartTokenizer.from_pretrained(tokenizer_path)\nmodel = BartForConditionalGeneration.from_pretrained(model_path)\nmodel.eval() \n\ndef generate_response(question):\n    input_ids = tokenizer(f\"question: {question} </s>\", return_tensors=\"pt\").input_ids.to(model.device)\n    outputs = model.generate(\n        input_ids,\n        max_length=128,\n        num_beams=5,  \n        no_repeat_ngram_size=2,  \n        top_k=50,  \n        top_p=0.95,  \n        temperature=1.0  \n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example usage\nresponse = generate_response(\"What causes brain cancer ?\")\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T17:08:34.020988Z","iopub.execute_input":"2024-11-28T17:08:34.021688Z","iopub.status.idle":"2024-11-28T17:08:42.017135Z","shell.execute_reply.started":"2024-11-28T17:08:34.021651Z","shell.execute_reply":"2024-11-28T17:08:42.016015Z"}},"outputs":[{"name":"stdout","text":"What causes brain cancer? Brain cancer is caused by a combination of genetic and environmental factors. The most common genetic cause is a mutation in the BRCA1 gene. This gene provides instructions for making a protein called bile duct beta-glucosaminidase, which is found in many tissues\n","output_type":"stream"}],"execution_count":21}]}